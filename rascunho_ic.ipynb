{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laisab/IC/blob/main/rascunho_ic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6owAqsajQua4",
        "outputId": "d54675ba-5099-479f-d1fe-3ff0d35e2ed5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from tabulate import tabulate"
      ],
      "metadata": {
        "id": "X7LBSzBFQ2B4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dicionário com datasets e seus respectivos targets\n",
        "dicio_datasets = {\n",
        "    'Adult.csv': 'income',\n",
        "    'Biomed.csv': 'class',\n",
        "    'COMPAS.csv': 'two_year_recid',\n",
        "    'ContraceptiveMethodChoice.csv': \"'Contraceptive_method_used'\",\n",
        "    'DefaultOfCreditCardClients.csv': 'default.payment.next.month',\n",
        "    'GermanCreditRisk.csv': \"class'\",\n",
        "    'HabermansSurvivalData.csv': \"'Survival_status'\",\n",
        "    'HeartDiseaseStatlog.csv': 'target',\n",
        "    'IndianLiverPatientDataset.csv': 'Class',\n",
        "    'IrishEducationalTransitionsData.csv': 'Leaving_Certificate',\n",
        "    'LowBirthWeightData.csv': 'binaryClass',\n",
        "    'PimaIndiansDiabetesDatabase.csv': \"'class'\",\n",
        "    'PopularKids.csv': 'Goals',\n",
        "    'PortugueseBankMarketing.csv': 'Subscription',\n",
        "    'Schizo.csv': 'class',\n",
        "    'SocialMobility.csv': 'binaryClass',\n",
        "    'ThyroidSicknessDetermination.csv': 'Class'\n",
        "}"
      ],
      "metadata": {
        "id": "o8dWzz60Q5pn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Idade**\n",
        "*   Menor de idade: < 18\n",
        "*   Jovem: 18 aos 30 anos\n",
        "*   Adulto: 31 aos 60 anos\n",
        "*   Idoso: acima dos 60 anos\n",
        "\n",
        "\n",
        "**Idade menor** (dataset PopularKids)\n",
        "*  Criança: <= 9 anos\n",
        "*  Pré-adolescente: 10 aos 13 anos\n",
        "*  Adolescente: > 13 anos\n",
        "\n",
        "**Educação** (dataset DefaultOfCreditCardClients)\n",
        "*   Pós-graduação: 1\n",
        "*   Universidade: 2\n",
        "*   Ensino médio: 3\n",
        "*   Outros: 4\n",
        "\n",
        "\n",
        "**Estado civil** (dataset DefaultOfCreditCardClients)\n",
        "*   Casado: 1\n",
        "*   Solteiro: 2\n",
        "*   Outros: 3\n",
        "*   Desconhecido: 0\n",
        "\n",
        "**Religião** (dataset ContraceptiveMethodChoice)\n",
        "*   Outras: 0\n",
        "*   Islamismo: 1\n",
        "\n",
        "**Esposa trabalha** (dataset ContraceptiveMethodChoice)\n",
        "*   Trabalha: 0\n",
        "*   Não trabalha: 1\n",
        "\n",
        "**Padrão de vida e nível de educação** (dataset ContraceptiveMethodChoice)\n",
        "*   Baixo: 1\n",
        "*   Médio-baixo: 2\n",
        "*   Médio-alto: 3\n",
        "*   Alto: 4\n",
        "\n",
        "**Raça** (dataset LowBirthWeightData)\n",
        "*   Branco: 1\n",
        "*   Preto: 2\n",
        "*   Outras: 3\n",
        "\n",
        "**Gênero**\n",
        "\n",
        "Para os datasets COMPAS e HeartDiseaseStatlog\n",
        "*   Mulher: 0\n",
        "*   Homem: 1\n",
        "\n",
        "Para o dataset DefaultOfCreditCardClients\n",
        "*   Homem: 1\n",
        "*   Mulher: 2"
      ],
      "metadata": {
        "id": "oljXNfmLkTpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idade = {\n",
        "    'bins': [14, 18, 30, 60, np.inf],\n",
        "    'labels': ['menor de idade', 'jovem', 'adulto', 'idoso']\n",
        "}\n",
        "\n",
        "idade_menor = {\n",
        "    'bins': [0, 9, 13, np.inf],\n",
        "    'labels': ['criança', 'pre-adolescente', 'adolescente']\n",
        "}\n",
        "\n",
        "educacao = {\n",
        "    1: 'pós-graduação',\n",
        "    2: 'universidade',\n",
        "    3: 'ensino médio',\n",
        "    4: 'outros'\n",
        "}\n",
        "\n",
        "estado_civil = {\n",
        "    1: 'casado',\n",
        "    2: 'solteiro',\n",
        "    3: 'outros',\n",
        "    0: 'desconhecido'\n",
        "}\n",
        "\n",
        "religiao = {\n",
        "    0: 'outras',\n",
        "    1: 'islamismo'\n",
        "}\n",
        "\n",
        "esposa_trabalha = {\n",
        "    0: 'trabalha',\n",
        "    1: 'não trabalha'\n",
        "}\n",
        "\n",
        "padrao_vida_educacao = {\n",
        "    1: 'baixo',\n",
        "    2: 'médio-baixo',\n",
        "    3: 'médio-alto',\n",
        "    4: 'alto'\n",
        "}\n",
        "\n",
        "raca = {\n",
        "    1: 'branco',\n",
        "    2: 'preto',\n",
        "    3: 'outros'\n",
        "}\n",
        "\n",
        "genero_1 = {\n",
        "    0: 'female',\n",
        "    1: 'male'\n",
        "}\n",
        "\n",
        "genero_2 = {\n",
        "    1: 'male',\n",
        "    2: 'female'\n",
        "}"
      ],
      "metadata": {
        "id": "7vW45-ppeSdG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dicionário com datasets e seus respectivos atributos sensíveis\n",
        "dicio_atributos_sensiveis = {\n",
        "    'Adult.csv': {\n",
        "        'age': idade,\n",
        "        'education': None,\n",
        "        'marital.status': None,\n",
        "        'relationship': None,\n",
        "        'race': None,\n",
        "        'sex': None,\n",
        "        'native.country': None\n",
        "    },\n",
        "\n",
        "    'Biomed.csv': {\n",
        "        'Age_of_patient': idade\n",
        "    },\n",
        "\n",
        "    'COMPAS.csv': {\n",
        "      'sex': genero_1,\n",
        "      'age': idade\n",
        "    },\n",
        "\n",
        "    'ContraceptiveMethodChoice.csv': {\n",
        "      \"'Wifes_age'\": idade,\n",
        "      \"'Wifes_education'\": padrao_vida_educacao,\n",
        "      \"'Husbands_education'\": padrao_vida_educacao,\n",
        "      \"'Wifes_religion'\": religiao,\n",
        "      \"'Wifes_now_working%3F'\": esposa_trabalha,\n",
        "      \"'Husbands_occupation'\": None,\n",
        "      \"'Standard-of-living_index'\": padrao_vida_educacao\n",
        "    },\n",
        "\n",
        "    'DefaultOfCreditCardClients.csv': {\n",
        "      'SEX': genero_2,\n",
        "      'EDUCATION': educacao,\n",
        "      'MARRIAGE': estado_civil,\n",
        "      'AGE': idade\n",
        "    },\n",
        "\n",
        "    'GermanCreditRisk.csv': {\n",
        "      \"personal_status'\": None,\n",
        "      \"age'\": idade,\n",
        "      \"housing'\": None,\n",
        "      \"job'\": None\n",
        "    },\n",
        "\n",
        "    'HabermansSurvivalData.csv': {\n",
        "      \"'Age_of_patient_at_time_of_operation'\": idade\n",
        "    },\n",
        "\n",
        "    'HeartDiseaseStatlog.csv': {\n",
        "      'age': idade,\n",
        "      'sex': genero_1\n",
        "    },\n",
        "\n",
        "    'IndianLiverPatientDataset.csv': {\n",
        "      'V1': idade,\n",
        "      'V2': None\n",
        "    },\n",
        "\n",
        "    'IrishEducationalTransitionsData.csv': {\n",
        "      'Sex': None,\n",
        "      'Prestige_score': None\n",
        "    },\n",
        "\n",
        "    'LowBirthWeightData.csv': {\n",
        "      'AGE': idade,\n",
        "      'RACE': raca,\n",
        "    },\n",
        "\n",
        "    'PimaIndiansDiabetesDatabase.csv': {\n",
        "      \"'age'\": idade,\n",
        "    },\n",
        "\n",
        "    'PopularKids.csv': {\n",
        "      'Gender': None,\n",
        "      'Age': idade_menor,\n",
        "      'Race': None,\n",
        "      'Urban/Rural': None\n",
        "    },\n",
        "\n",
        "    'PortugueseBankMarketing.csv': {\n",
        "      'Age': idade,\n",
        "      'Job': None,\n",
        "      'Marital Status': None,\n",
        "      'Education': None\n",
        "    },\n",
        "\n",
        "    'Schizo.csv': {\n",
        "      'sex': None\n",
        "    },\n",
        "\n",
        "    'SocialMobility.csv': {\n",
        "      'family_structure': None,\n",
        "      'race': None\n",
        "    },\n",
        "\n",
        "    'ThyroidSicknessDetermination.csv': {\n",
        "      'age': None,\n",
        "      'sex': None\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "FYE2XQ7reZhX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "caminho_drive = '/content/drive/MyDrive/IC/Datasets/'\n",
        "novo_caminho = '/content/drive/MyDrive/Teste/'\n",
        "caminho_resultados = '/content/drive/MyDrive/Teste/Testando/'"
      ],
      "metadata": {
        "id": "cqOCCj6QQ6-g"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Formatação dos dados\n",
        "def formatar_dados(resultados_para_formatacao):\n",
        "  formatado = {}\n",
        "\n",
        "  for chave, valor in resultados_para_formatacao.items():\n",
        "    if isinstance(valor, (int, float)):\n",
        "      formatado[chave] = f'{valor:.3f}' if not pd.isna(valor) else \"NaN\"\n",
        "    else:\n",
        "      formatado[chave] = valor\n",
        "\n",
        "  return formatado"
      ],
      "metadata": {
        "id": "do7988sXVtlD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separação das features e target\n",
        "def separar_feature_target(caminho_completo):\n",
        "\n",
        "  try:\n",
        "    df = pd.read_csv(caminho_completo)\n",
        "\n",
        "    # Obtém o nome do target\n",
        "    nome_arquivo = os.path.basename(caminho_completo)\n",
        "    nome_target = dicio_datasets.get(nome_arquivo)\n",
        "\n",
        "    if not nome_target:\n",
        "      raise ValueError(f'Coluna target não encontrada para o arquivo {nome_arquivo}')\n",
        "\n",
        "    # Separa features (X) e target (y)\n",
        "    X = df.drop(columns=[nome_target])\n",
        "    y = df[nome_target]\n",
        "\n",
        "    # Dicionário para armazenar o mapeamento de colunas OneHotEncoder\n",
        "    # Exemplo: {'sex': ['sex_female', 'sex_male']}\n",
        "    colunas_onehot = {}\n",
        "\n",
        "    # Codificação de features categóricas com OneHotEncoder\n",
        "    colunas_categoricas = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "    # Verificação de colunas categóricas para evitar erros com datasets numéricos\n",
        "    if colunas_categoricas.size > 0:\n",
        "      # Lida com categorias desconhecidas em dados futuros\n",
        "      enc = OneHotEncoder(handle_unknown='ignore')\n",
        "      X_encoded = enc.fit_transform(X[colunas_categoricas]).toarray()\n",
        "\n",
        "      # Nomes das novas features criadas pelo OneHotEncoder\n",
        "      novo_nome_X = enc.get_feature_names_out(colunas_categoricas)\n",
        "      X_encoded_df = pd.DataFrame(X_encoded, columns=novo_nome_X)\n",
        "\n",
        "      # Para cada coluna categórica original, a lista das novas colunas são armazenadas\n",
        "      for coluna_original in colunas_categoricas:\n",
        "        # Dicionário \"colunas_onehot\" => coluna_original é a chave e a lista é o valor\n",
        "        colunas_onehot[coluna_original] = [nome for nome in novo_nome_X if nome.startswith(f'{coluna_original}_')]\n",
        "\n",
        "      # Remove as colunas categóricas originais\n",
        "      X = X.select_dtypes(exclude=['object'])\n",
        "      X = pd.concat([X, X_encoded_df], axis=1)\n",
        "\n",
        "    return X, y, colunas_onehot\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f'\\nErro ao separar os dados de {nome_arquivo}: {e}')\n",
        "    return None"
      ],
      "metadata": {
        "id": "vrRvH6M0Q9r_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predição dos datasets\n",
        "def predizer_dataset(modelo, X, y, cv):\n",
        "  try:\n",
        "    y_pred = cross_val_predict(modelo, X, y, cv=cv, method='predict')\n",
        "    y_prob = cross_val_predict(modelo, X, y, cv=cv, method='predict_proba')\n",
        "    return y_pred, y_prob\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f'\\nErro ao predizer dataset: {e}')\n",
        "    return None"
      ],
      "metadata": {
        "id": "f_unc5YTQ_HP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliação dos datasets\n",
        "def avaliar_dataset(y, y_pred, y_prob):\n",
        "  try:\n",
        "    metricas = {\n",
        "      'accuracy': accuracy_score,\n",
        "      'f1_score': lambda y_true, y_pred: f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
        "      'roc_auc_score': lambda y_true, y_pred_proba: roc_auc_score(y_true, y_pred_proba, average='macro', multi_class='ovr') if len(np.unique(y_true)) > 2 else (roc_auc_score(y_true, y_pred_proba[:, 1]) if len(np.unique(y_true)) == 2 else np.nan)\n",
        "    }\n",
        "\n",
        "    avaliacao = {}\n",
        "    for metrica, metrica_funcao in metricas.items():\n",
        "      try:\n",
        "        if metrica == 'roc_auc_score':\n",
        "          # AUC não é calculada para target com menos de 2 classes únicas\n",
        "          if len(np.unique(y)) < 2:\n",
        "            avaliacao[metrica] = np.nan\n",
        "          else:\n",
        "            avaliacao[metrica] = metrica_funcao(y, y_prob)\n",
        "        else:\n",
        "          avaliacao[metrica] = metrica_funcao(y, y_pred)\n",
        "      except Exception as e:\n",
        "        print(f'\\nErro ao calcular {metrica}: {e}')\n",
        "        avaliacao[metrica] = None\n",
        "\n",
        "    return avaliacao\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f'\\nErro ao avaliar dataset: {e}')\n",
        "    return None"
      ],
      "metadata": {
        "id": "7eHoRSIElfep"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliação dos segmentos\n",
        "def avaliar_segmentos(X, y, y_pred, y_prob, X_onehot, avaliar_dataset_func, auc_geral, dataset=\"\", atr_sensivel=None, num_bins=5):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    X: features\n",
        "    y: target\n",
        "    y_pred: predições\n",
        "    y_prob: probabilidades\n",
        "    X_onehot: colunas OneHotEncoder\n",
        "    avaliar_dataset_func: função avaliar_dataset\n",
        "    dataset: nome do dataset\n",
        "    atributos_sensiveis: dicionário com atributos sensíveis\n",
        "    bins: número de segmentos para atributos numéricos sem label (padrão = 5)\n",
        "  \"\"\"\n",
        "\n",
        "  res_segmentos = []\n",
        "\n",
        "  for coluna_original, bin_labels in atr_sensivel.items():\n",
        "    if coluna_original not in X.columns and coluna_original not in X_onehot:\n",
        "      print(f'  Atributo {coluna_original} não encontrado para o dataset {dataset}')\n",
        "      continue\n",
        "\n",
        "    # print(f'\\n  Avaliação dos segmentos para o atributo {coluna_original} do dataset {dataset}')\n",
        "\n",
        "    # Atributos transformados pelo OneHotEncoder\n",
        "    if coluna_original in X_onehot:\n",
        "      colunas_onehot = X_onehot[coluna_original] # Lista das colunas geradas pelo OneHot\n",
        "\n",
        "      for coluna_onehot in colunas_onehot:\n",
        "        idx = X[coluna_onehot] == 1\n",
        "\n",
        "        if idx.sum() > 0:\n",
        "          # Subconjuntos para o segmento atual\n",
        "          subset_y = y[idx]\n",
        "          subset_y_pred = y_pred[idx]\n",
        "          subset_y_prob = y_prob[idx]\n",
        "\n",
        "          # Extrai o nome original da categoria\n",
        "          nome_categorico = coluna_onehot.replace(f'{coluna_original}_', '')\n",
        "\n",
        "          # print(f'  Segmento {nome_categorico}')\n",
        "          avaliacao = avaliar_dataset_func(subset_y, subset_y_pred, subset_y_prob)\n",
        "          avaliacao_formatada = formatar_dados(avaliacao)\n",
        "          # print(avaliacao_formatada)\n",
        "\n",
        "          auc_segmento = avaliacao.get('roc_auc_score')\n",
        "          diferenca_auc = np.nan\n",
        "\n",
        "          auc_geral_formatada = f'{auc_geral:.3f}' if not pd.isna(auc_geral) else \"NaN\"\n",
        "\n",
        "          if auc_segmento is not None and auc_geral is not None and not np.isnan(auc_segmento) and not np.isnan(auc_geral) and auc_geral != 0:\n",
        "            diferenca_auc = ((auc_geral - auc_segmento) / auc_geral) * 100\n",
        "\n",
        "          diferenca_auc_formatada = f'{diferenca_auc:.2f}' if not pd.isna(diferenca_auc) else \"NaN\"\n",
        "\n",
        "          # Número de instância do segmento\n",
        "          n_instancias = idx.sum()\n",
        "          n_instancias_porcentagem = f'{n_instancias / len(y) * 100:.3f}'\n",
        "\n",
        "          res_segmentos.append([coluna_original, nome_categorico, avaliacao_formatada.get('accuracy'), avaliacao_formatada.get('f1_score'), avaliacao_formatada.get('roc_auc_score'), auc_geral_formatada, diferenca_auc_formatada, n_instancias, n_instancias_porcentagem])\n",
        "        else:\n",
        "          nome_categorico = coluna_onehot.replace(f'{coluna_original}_', '')\n",
        "          print(f'  Segmento {nome_categorico} sem dados (com OneHot)')\n",
        "          res_segmentos.append([coluna_original, nome_categorico, None, None, None, None, None])\n",
        "\n",
        "    # Atributos sem OneHotEncoder (numéricos ou categóricos que não passaram pelo OneHot)\n",
        "    else:\n",
        "      # Obtém a coluna do dataset que corresponde ao atributo sensível\n",
        "      coluna_dataset = X[coluna_original]\n",
        "      # Inicializa com os valores da coluna original\n",
        "      bin_col = coluna_dataset\n",
        "\n",
        "      classificacao = atr_sensivel.get(coluna_original)\n",
        "\n",
        "      # Valores de classificação como um dicionário\n",
        "      if isinstance(classificacao, dict) and 'bins' not in classificacao:\n",
        "        bin_col = coluna_dataset.map(classificacao).fillna(coluna_dataset)\n",
        "\n",
        "      # Bins configurados\n",
        "      elif isinstance(classificacao, dict) and 'bins' in classificacao:\n",
        "        try:\n",
        "          bin_col = pd.cut(coluna_dataset, bins=bin_labels['bins'], labels=bin_labels['labels'], include_lowest=True, right=True)\n",
        "        except Exception as e:\n",
        "          print(f'  Erro ao configurar os bins para o atributo {coluna_original}: {e}')\n",
        "          # Mantém o bin_col como a coluna original\n",
        "          bin_col = coluna_dataset\n",
        "          continue\n",
        "\n",
        "      # Bins automáticos\n",
        "      elif classificacao is None and pd.api.types.is_numeric_dtype(coluna_dataset) and len(coluna_dataset.unique()) > num_bins * 2:\n",
        "        try:\n",
        "          bin_col = pd.qcut(coluna_dataset, q=num_bins, duplicates='drop')\n",
        "        except Exception as e:\n",
        "          print(f'  Erro ao configurar os bins para o atributo {coluna_original}: {e}')\n",
        "          # Mantém o bin_col como a coluna original\n",
        "          bin_col = coluna_dataset\n",
        "          continue\n",
        "\n",
        "      # Valores únicos da coluna (original ou após bins de classificação)\n",
        "      valor_unico = bin_col.unique().tolist()\n",
        "\n",
        "      # Ordenação dos valores únicos para os intervalos\n",
        "      try:\n",
        "        valor_unico.sort(key=lambda x: x.left if isinstance(x, pd.Interval) else x)\n",
        "      except TypeError:\n",
        "        # Tentativa de ordenação por conversão para string\n",
        "        try:\n",
        "          valor_unico.sort(key=str)\n",
        "        except TypeError:\n",
        "          pass\n",
        "\n",
        "      for valor in valor_unico:\n",
        "        idx = bin_col == valor\n",
        "\n",
        "        if idx.sum() > 0:\n",
        "          # Subconjuntos para o segmento atual\n",
        "          subset_y = y[idx]\n",
        "          subset_y_pred = y_pred[idx]\n",
        "          subset_y_prob = y_prob[idx]\n",
        "\n",
        "          # Definição do nome do grupo como a string do valor ou do bin\n",
        "          nome_grupo = str(valor)\n",
        "\n",
        "          # print(f'  Segmento {nome_grupo}')\n",
        "          avaliacao = avaliar_dataset_func(subset_y, subset_y_pred, subset_y_prob)\n",
        "          avaliacao_formatada = formatar_dados(avaliacao)\n",
        "          # print(avaliacao_formatada)\n",
        "\n",
        "          auc_segmento = avaliacao.get('roc_auc_score')\n",
        "          diferenca_auc = np.nan\n",
        "\n",
        "          auc_geral_formatada = f'{auc_geral:.3f}' if not pd.isna(auc_geral) else \"NaN\"\n",
        "\n",
        "          if auc_segmento is not None and auc_geral is not None and not np.isnan(auc_segmento) and not np.isnan(auc_geral) and auc_geral != 0:\n",
        "            diferenca_auc = ((auc_geral - auc_segmento) / auc_geral) * 100\n",
        "\n",
        "          diferenca_auc_formatada = f'{diferenca_auc:.2f}' if not pd.isna(diferenca_auc) else \"NaN\"\n",
        "\n",
        "          # Número de instância do segmento\n",
        "          n_instancias = idx.sum()\n",
        "          n_instancias_porcentagem = f'{n_instancias / len(y) * 100:.3f}'\n",
        "\n",
        "          res_segmentos.append([coluna_original, nome_grupo, avaliacao_formatada.get('accuracy'), avaliacao_formatada.get('f1_score'), avaliacao_formatada.get('roc_auc_score'), auc_geral_formatada, diferenca_auc_formatada, n_instancias, n_instancias_porcentagem])\n",
        "        else:\n",
        "          nome_grupo = str(valor)\n",
        "          print(f'  Segmento {nome_grupo} sem dados (sem One Hot)')\n",
        "          res_segmentos.append([coluna_original, nome_grupo, None, None, None, None, None])\n",
        "\n",
        "  return pd.DataFrame(res_segmentos, columns=['ATRIBUTO', 'SEGMENTO', 'ACURÁCIA', 'F1', 'AUC SEGMENTO', 'AUC DATASET', 'DIFERENÇA AUC (%)', 'NÚMERO DE INSTÂNCIAS', 'NÚMERO DE INSTÂNCIAS (%)'])"
      ],
      "metadata": {
        "id": "YWXRm9bbikwb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista os arquivos csv na pasta\n",
        "arquivos = [f for f in os.listdir(caminho_drive) if f.endswith('.csv') and f in dicio_datasets]\n",
        "arquivos"
      ],
      "metadata": {
        "id": "SK9FRq2DRBiv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ccd9d60-616d-404c-e839-10e7817dc7c4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['IndianLiverPatientDataset.csv',\n",
              " 'HabermansSurvivalData.csv',\n",
              " 'GermanCreditRisk.csv',\n",
              " 'PortugueseBankMarketing.csv',\n",
              " 'DefaultOfCreditCardClients.csv',\n",
              " 'Adult.csv',\n",
              " 'COMPAS.csv',\n",
              " 'ContraceptiveMethodChoice.csv',\n",
              " 'ThyroidSicknessDetermination.csv',\n",
              " 'HeartDiseaseStatlog.csv',\n",
              " 'SocialMobility.csv',\n",
              " 'LowBirthWeightData.csv',\n",
              " 'PopularKids.csv',\n",
              " 'IrishEducationalTransitionsData.csv',\n",
              " 'Biomed.csv',\n",
              " 'Schizo.csv',\n",
              " 'PimaIndiansDiabetesDatabase.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Processamento de cada dataset - RandomForest\n",
        "resultados_dataset = []\n",
        "res_metrica_tabela = []\n",
        "\n",
        "modelo = RandomForestClassifier(n_estimators=20, random_state=42)\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for arquivo in arquivos:\n",
        "  caminho_completo = os.path.join(caminho_drive, arquivo)\n",
        "  dados = separar_feature_target(caminho_completo)\n",
        "\n",
        "  if dados is not None:\n",
        "    X, y, X_onehot = dados\n",
        "    predicao, probabilidade = predizer_dataset(modelo, X, y, cv)\n",
        "    resultados_dataset = avaliar_dataset(y, predicao, probabilidade)\n",
        "    resultados_dataset_formatados = formatar_dados(resultados_dataset)\n",
        "    # print(f'\\n  Resultados do dataset {arquivo}: {resultados_dataset_formatados}')\n",
        "\n",
        "    res_metrica_tabela.append([\n",
        "      arquivo,\n",
        "      str(modelo).split('(')[0],\n",
        "      resultados_dataset_formatados.get('accuracy'),\n",
        "      resultados_dataset_formatados.get('f1_score'),\n",
        "      resultados_dataset_formatados.get('roc_auc_score')\n",
        "    ])\n",
        "\n",
        "    auc_geral = resultados_dataset.get('roc_auc_score')\n",
        "\n",
        "    arquivo_pred = f\"Predicao_{arquivo}\"\n",
        "    caminho_pred = os.path.join(novo_caminho, arquivo_pred)\n",
        "    pd.DataFrame(predicao, columns=[arquivo]).to_csv(caminho_pred, index=False)\n",
        "\n",
        "    df_segmentos = avaliar_segmentos(X, y, predicao, probabilidade, X_onehot, avaliar_dataset, auc_geral, arquivo, dicio_atributos_sensiveis.get(arquivo, {}), 5)\n",
        "\n",
        "    if not df_segmentos.empty:\n",
        "      df_segmentos['num_dif_auc'] = pd.to_numeric(\n",
        "          df_segmentos['DIFERENÇA AUC (%)'],\n",
        "          errors='coerce'\n",
        "      )\n",
        "\n",
        "      df_segmentos = df_segmentos.sort_values(\n",
        "          by='num_dif_auc',\n",
        "          ascending=False,\n",
        "          na_position='last'\n",
        "      )\n",
        "\n",
        "      df_segmentos = df_segmentos.drop(columns=['num_dif_auc'])\n",
        "\n",
        "    nome_dataset = arquivo.replace('.csv', '')\n",
        "    arquivo_segmento = f\"Segmentos_{nome_dataset}_RF.csv\"\n",
        "    caminho_segmento = os.path.join(caminho_resultados + \"RandomForest/\", arquivo_segmento)\n",
        "    df_segmentos.to_csv(caminho_segmento, index=False)\n",
        "  else:\n",
        "    print(f'Não foi possível processar o dataset {arquivo}')"
      ],
      "metadata": {
        "id": "ZfKNIi7qRDqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1026f00-233e-4769-a3c1-4633e191c439"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Segmento nan sem dados (sem One Hot)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "colunas = ['NOME DO DATASET', 'MODELO', 'ACURÁCIA', 'F1', 'AUC']\n",
        "print(tabulate(res_metrica_tabela, headers=colunas, tablefmt='fancy_grid'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmQcf6tCk0EJ",
        "outputId": "4bb49f17-abb1-48d4-8aab-472135732baa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒═════════════════════════════════════╤════════════════════════╤════════════╤═══════╤═══════╕\n",
            "│ NOME DO DATASET                     │ MODELO                 │   ACURÁCIA │    F1 │   AUC │\n",
            "╞═════════════════════════════════════╪════════════════════════╪════════════╪═══════╪═══════╡\n",
            "│ IndianLiverPatientDataset.csv       │ RandomForestClassifier │      0.707 │ 0.576 │ 0.745 │\n",
            "├─────────────────────────────────────┼────────────────────────┼────────────┼───────┼───────┤\n",
            "│ HabermansSurvivalData.csv           │ RandomForestClassifier │      0.699 │ 0.565 │ 0.621 │\n",
            "├─────────────────────────────────────┼────────────────────────┼────────────┼───────┼───────┤\n",
            "│ GermanCreditRisk.csv                │ RandomForestClassifier │      0.744 │ 0.66  │ 0.76  │\n",
            "├─────────────────────────────────────┼────────────────────────┼────────────┼───────┼───────┤\n",
            "│ PortugueseBankMarketing.csv         │ RandomForestClassifier │      0.903 │ 0.712 │ 0.913 │\n",
            "├─────────────────────────────────────┼────────────────────────┼────────────┼───────┼───────┤\n",
            "│ DefaultOfCreditCardClients.csv      │ RandomForestClassifier │      0.812 │ 0.667 │ 0.751 │\n",
            "├─────────────────────────────────────┼────────────────────────┼────────────┼───────┼───────┤\n",
            "│ Adult.csv                           │ RandomForestClassifier │      0.85  │ 0.781 │ 0.892 │\n",
            "├─────────────────────────────────────┼────────────────────────┼────────────┼───────┼───────┤\n",
            "│ COMPAS.csv                          │ RandomForestClassifier │      0.637 │ 0.634 │ 0.674 │\n",
            "├─────────────────────────────────────┼────────────────────────┼────────────┼───────┼───────┤\n",
            "│ ContraceptiveMethodChoice.csv       │ RandomForestClassifier │      0.972 │ 0.969 │ 0.998 │\n",
            "├─────────────────────────────────────┼────────────────────────┼────────────┼───────┼───────┤\n",
            "│ ThyroidSicknessDetermination.csv    │ RandomForestClassifier │      0.961 │ 0.789 │ 0.939 │\n",
            "├─────────────────────────────────────┼────────────────────────┼────────────┼───────┼───────┤\n",
            "│ HeartDiseaseStatlog.csv             │ RandomForestClassifier │      0.807 │ 0.803 │ 0.875 │\n",
            "├─────────────────────────────────────┼────────────────────────┼────────────┼───────┼───────┤\n",
            "│ SocialMobility.csv                  │ RandomForestClassifier │      0.94  │ 0.913 │ 0.983 │\n",
            "├─────────────────────────────────────┼────────────────────────┼────────────┼───────┼───────┤\n",
            "│ LowBirthWeightData.csv              │ RandomForestClassifier │      0.995 │ 0.995 │ 1     │\n",
            "├─────────────────────────────────────┼────────────────────────┼────────────┼───────┼───────┤\n",
            "│ PopularKids.csv                     │ RandomForestClassifier │      0.519 │ 0.446 │ 0.641 │\n",
            "├─────────────────────────────────────┼────────────────────────┼────────────┼───────┼───────┤\n",
            "│ IrishEducationalTransitionsData.csv │ RandomForestClassifier │      0.998 │ 0.998 │ 1     │\n",
            "├─────────────────────────────────────┼────────────────────────┼────────────┼───────┼───────┤\n",
            "│ Biomed.csv                          │ RandomForestClassifier │      1     │ 1     │ 1     │\n",
            "├─────────────────────────────────────┼────────────────────────┼────────────┼───────┼───────┤\n",
            "│ Schizo.csv                          │ RandomForestClassifier │      0.991 │ 0.991 │ 1     │\n",
            "├─────────────────────────────────────┼────────────────────────┼────────────┼───────┼───────┤\n",
            "│ PimaIndiansDiabetesDatabase.csv     │ RandomForestClassifier │      0.763 │ 0.727 │ 0.815 │\n",
            "╘═════════════════════════════════════╧════════════════════════╧════════════╧═══════╧═══════╛\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Processamento de cada dataset - KNN\n",
        "resultados_dataset = []\n",
        "res_metrica_tabela = []\n",
        "\n",
        "modelo = KNeighborsClassifier(n_neighbors=5)\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for arquivo in arquivos:\n",
        "  caminho_completo = os.path.join(caminho_drive, arquivo)\n",
        "  dados = separar_feature_target(caminho_completo)\n",
        "\n",
        "  if dados is not None:\n",
        "    X, y, X_onehot = dados\n",
        "    predicao, probabilidade = predizer_dataset(modelo, X, y, cv)\n",
        "    resultados_dataset = avaliar_dataset(y, predicao, probabilidade)\n",
        "    resultados_dataset_formatados = formatar_dados(resultados_dataset)\n",
        "    # print(f'\\n  Resultados do dataset {arquivo}: {resultados_dataset_formatados}')\n",
        "\n",
        "    res_metrica_tabela.append([\n",
        "      arquivo,\n",
        "      str(modelo).split('(')[0],\n",
        "      resultados_dataset_formatados.get('accuracy'),\n",
        "      resultados_dataset_formatados.get('f1_score'),\n",
        "      resultados_dataset_formatados.get('roc_auc_score')\n",
        "    ])\n",
        "\n",
        "    auc_geral = resultados_dataset.get('roc_auc_score')\n",
        "\n",
        "    \"\"\"\n",
        "    arquivo_pred = f\"Predicao_{arquivo}\"\n",
        "    caminho_pred = os.path.join(novo_caminho, arquivo_pred)\n",
        "    pd.DataFrame(predicao, columns=[arquivo]).to_csv(caminho_pred, index=False)\n",
        "    \"\"\"\n",
        "\n",
        "    df_segmentos = avaliar_segmentos(X, y, predicao, probabilidade, X_onehot, avaliar_dataset, auc_geral, arquivo, dicio_atributos_sensiveis.get(arquivo, {}), 5)\n",
        "\n",
        "    nome_dataset = arquivo.replace('.csv', '')\n",
        "    arquivo_segmento = f\"Segmentos_{nome_dataset}_KNN.csv\"\n",
        "    caminho_segmento = os.path.join(caminho_resultados + \"KNN/\", arquivo_segmento)\n",
        "    df_segmentos.to_csv(caminho_segmento, index=False)\n",
        "  else:\n",
        "    print(f'Não foi possível processar o dataset {arquivo}')"
      ],
      "metadata": {
        "id": "bSGBhdhFYQRg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69164af5-4f62-42b4-8008-38d6fe4ac0f1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Segmento nan sem dados (sem One Hot)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "colunas = ['NOME DO DATASET', 'MODELO', 'ACURÁCIA', 'F1', 'AUC']\n",
        "print(tabulate(res_metrica_tabela, headers=colunas, tablefmt='fancy_grid'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHExQJlEYjCA",
        "outputId": "438f002d-392f-49b7-cda1-1c01e638a2f3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒═════════════════════════════════════╤══════════════════════╤════════════╤═══════╤═══════╕\n",
            "│ NOME DO DATASET                     │ MODELO               │   ACURÁCIA │    F1 │   AUC │\n",
            "╞═════════════════════════════════════╪══════════════════════╪════════════╪═══════╪═══════╡\n",
            "│ IndianLiverPatientDataset.csv       │ KNeighborsClassifier │      0.65  │ 0.513 │ 0.603 │\n",
            "├─────────────────────────────────────┼──────────────────────┼────────────┼───────┼───────┤\n",
            "│ HabermansSurvivalData.csv           │ KNeighborsClassifier │      0.703 │ 0.506 │ 0.541 │\n",
            "├─────────────────────────────────────┼──────────────────────┼────────────┼───────┼───────┤\n",
            "│ GermanCreditRisk.csv                │ KNeighborsClassifier │      0.627 │ 0.484 │ 0.501 │\n",
            "├─────────────────────────────────────┼──────────────────────┼────────────┼───────┼───────┤\n",
            "│ PortugueseBankMarketing.csv         │ KNeighborsClassifier │      0.882 │ 0.642 │ 0.765 │\n",
            "├─────────────────────────────────────┼──────────────────────┼────────────┼───────┼───────┤\n",
            "│ DefaultOfCreditCardClients.csv      │ KNeighborsClassifier │      0.75  │ 0.545 │ 0.599 │\n",
            "├─────────────────────────────────────┼──────────────────────┼────────────┼───────┼───────┤\n",
            "│ Adult.csv                           │ KNeighborsClassifier │      0.777 │ 0.635 │ 0.671 │\n",
            "├─────────────────────────────────────┼──────────────────────┼────────────┼───────┼───────┤\n",
            "│ COMPAS.csv                          │ KNeighborsClassifier │      0.551 │ 0.546 │ 0.564 │\n",
            "├─────────────────────────────────────┼──────────────────────┼────────────┼───────┼───────┤\n",
            "│ ContraceptiveMethodChoice.csv       │ KNeighborsClassifier │      0.992 │ 0.991 │ 1     │\n",
            "├─────────────────────────────────────┼──────────────────────┼────────────┼───────┼───────┤\n",
            "│ ThyroidSicknessDetermination.csv    │ KNeighborsClassifier │      0.948 │ 0.641 │ 0.837 │\n",
            "├─────────────────────────────────────┼──────────────────────┼────────────┼───────┼───────┤\n",
            "│ HeartDiseaseStatlog.csv             │ KNeighborsClassifier │      0.633 │ 0.626 │ 0.68  │\n",
            "├─────────────────────────────────────┼──────────────────────┼────────────┼───────┼───────┤\n",
            "│ SocialMobility.csv                  │ KNeighborsClassifier │      0.907 │ 0.863 │ 0.949 │\n",
            "├─────────────────────────────────────┼──────────────────────┼────────────┼───────┼───────┤\n",
            "│ LowBirthWeightData.csv              │ KNeighborsClassifier │      0.947 │ 0.947 │ 0.993 │\n",
            "├─────────────────────────────────────┼──────────────────────┼────────────┼───────┼───────┤\n",
            "│ PopularKids.csv                     │ KNeighborsClassifier │      0.529 │ 0.449 │ 0.648 │\n",
            "├─────────────────────────────────────┼──────────────────────┼────────────┼───────┼───────┤\n",
            "│ IrishEducationalTransitionsData.csv │ KNeighborsClassifier │      0.712 │ 0.708 │ 0.747 │\n",
            "├─────────────────────────────────────┼──────────────────────┼────────────┼───────┼───────┤\n",
            "│ Biomed.csv                          │ KNeighborsClassifier │      0.809 │ 0.782 │ 0.887 │\n",
            "├─────────────────────────────────────┼──────────────────────┼────────────┼───────┼───────┤\n",
            "│ Schizo.csv                          │ KNeighborsClassifier │      1     │ 1     │ 1     │\n",
            "├─────────────────────────────────────┼──────────────────────┼────────────┼───────┼───────┤\n",
            "│ PimaIndiansDiabetesDatabase.csv     │ KNeighborsClassifier │      0.681 │ 0.626 │ 0.694 │\n",
            "╘═════════════════════════════════════╧══════════════════════╧════════════╧═══════╧═══════╛\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Processamento de cada dataset - GradientBoostingClassifier\n",
        "resultados_dataset = []\n",
        "res_metrica_tabela = []\n",
        "\n",
        "modelo = GradientBoostingClassifier(n_estimators=20, random_state=42)\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for arquivo in arquivos:\n",
        "  caminho_completo = os.path.join(caminho_drive, arquivo)\n",
        "  dados = separar_feature_target(caminho_completo)\n",
        "\n",
        "  if dados is not None:\n",
        "    X, y, X_onehot = dados\n",
        "    predicao, probabilidade = predizer_dataset(modelo, X, y, cv)\n",
        "    resultados_dataset = avaliar_dataset(y, predicao, probabilidade)\n",
        "    resultados_dataset_formatados = formatar_dados(resultados_dataset)\n",
        "    # print(f'\\n  Resultados do dataset {arquivo}: {resultados_dataset_formatados}')\n",
        "\n",
        "    res_metrica_tabela.append([\n",
        "      arquivo,\n",
        "      str(modelo).split('(')[0],\n",
        "      resultados_dataset_formatados.get('accuracy'),\n",
        "      resultados_dataset_formatados.get('f1_score'),\n",
        "      resultados_dataset_formatados.get('roc_auc_score')\n",
        "    ])\n",
        "\n",
        "    auc_geral = resultados_dataset.get('roc_auc_score')\n",
        "\n",
        "    \"\"\"\n",
        "    arquivo_pred = f\"Predicao_{arquivo}\"\n",
        "    caminho_pred = os.path.join(novo_caminho, arquivo_pred)\n",
        "    pd.DataFrame(predicao, columns=[arquivo]).to_csv(caminho_pred, index=False)\n",
        "    \"\"\"\n",
        "\n",
        "    df_segmentos = avaliar_segmentos(X, y, predicao, probabilidade, X_onehot, avaliar_dataset, auc_geral, arquivo, dicio_atributos_sensiveis.get(arquivo, {}), 5)\n",
        "\n",
        "    nome_dataset = arquivo.replace('.csv', '')\n",
        "    arquivo_segmento = f\"Segmentos_{nome_dataset}_GB.csv\"\n",
        "    caminho_segmento = os.path.join(caminho_resultados + \"GradientBoosting/\", arquivo_segmento)\n",
        "    df_segmentos.to_csv(caminho_segmento, index=False)\n",
        "  else:\n",
        "    print(f'Não foi possível processar o dataset {arquivo}')"
      ],
      "metadata": {
        "id": "BGFPDC-TYsug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8538b5f-76f3-44a2-87b5-c767e54b14d3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Segmento nan sem dados (sem One Hot)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "colunas = ['NOME DO DATASET', 'MODELO', 'ACURÁCIA', 'F1', 'AUC']\n",
        "print(tabulate(res_metrica_tabela, headers=colunas, tablefmt='fancy_grid'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxBw-O5qYyy_",
        "outputId": "ba0e6e93-7db1-409e-dcbf-ac187a0c3dcd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒═════════════════════════════════════╤════════════════════════════╤════════════╤═══════╤═══════╕\n",
            "│ NOME DO DATASET                     │ MODELO                     │   ACURÁCIA │    F1 │   AUC │\n",
            "╞═════════════════════════════════════╪════════════════════════════╪════════════╪═══════╪═══════╡\n",
            "│ IndianLiverPatientDataset.csv       │ GradientBoostingClassifier │      0.695 │ 0.491 │ 0.731 │\n",
            "├─────────────────────────────────────┼────────────────────────────┼────────────┼───────┼───────┤\n",
            "│ HabermansSurvivalData.csv           │ GradientBoostingClassifier │      0.765 │ 0.622 │ 0.686 │\n",
            "├─────────────────────────────────────┼────────────────────────────┼────────────┼───────┼───────┤\n",
            "│ GermanCreditRisk.csv                │ GradientBoostingClassifier │      0.744 │ 0.607 │ 0.754 │\n",
            "├─────────────────────────────────────┼────────────────────────────┼────────────┼───────┼───────┤\n",
            "│ PortugueseBankMarketing.csv         │ GradientBoostingClassifier │      0.898 │ 0.649 │ 0.897 │\n",
            "├─────────────────────────────────────┼────────────────────────────┼────────────┼───────┼───────┤\n",
            "│ DefaultOfCreditCardClients.csv      │ GradientBoostingClassifier │      0.821 │ 0.675 │ 0.772 │\n",
            "├─────────────────────────────────────┼────────────────────────────┼────────────┼───────┼───────┤\n",
            "│ Adult.csv                           │ GradientBoostingClassifier │      0.851 │ 0.762 │ 0.904 │\n",
            "├─────────────────────────────────────┼────────────────────────────┼────────────┼───────┼───────┤\n",
            "│ COMPAS.csv                          │ GradientBoostingClassifier │      0.684 │ 0.68  │ 0.734 │\n",
            "├─────────────────────────────────────┼────────────────────────────┼────────────┼───────┼───────┤\n",
            "│ ContraceptiveMethodChoice.csv       │ GradientBoostingClassifier │      0.997 │ 0.997 │ 0.997 │\n",
            "├─────────────────────────────────────┼────────────────────────────┼────────────┼───────┼───────┤\n",
            "│ ThyroidSicknessDetermination.csv    │ GradientBoostingClassifier │      0.962 │ 0.791 │ 0.925 │\n",
            "├─────────────────────────────────────┼────────────────────────────┼────────────┼───────┼───────┤\n",
            "│ HeartDiseaseStatlog.csv             │ GradientBoostingClassifier │      0.8   │ 0.794 │ 0.862 │\n",
            "├─────────────────────────────────────┼────────────────────────────┼────────────┼───────┼───────┤\n",
            "│ SocialMobility.csv                  │ GradientBoostingClassifier │      0.95  │ 0.924 │ 0.978 │\n",
            "├─────────────────────────────────────┼────────────────────────────┼────────────┼───────┼───────┤\n",
            "│ LowBirthWeightData.csv              │ GradientBoostingClassifier │      0.995 │ 0.995 │ 0.999 │\n",
            "├─────────────────────────────────────┼────────────────────────────┼────────────┼───────┼───────┤\n",
            "│ PopularKids.csv                     │ GradientBoostingClassifier │      0.571 │ 0.453 │ 0.669 │\n",
            "├─────────────────────────────────────┼────────────────────────────┼────────────┼───────┼───────┤\n",
            "│ IrishEducationalTransitionsData.csv │ GradientBoostingClassifier │      1     │ 1     │ 1     │\n",
            "├─────────────────────────────────────┼────────────────────────────┼────────────┼───────┼───────┤\n",
            "│ Biomed.csv                          │ GradientBoostingClassifier │      0.995 │ 0.995 │ 0.995 │\n",
            "├─────────────────────────────────────┼────────────────────────────┼────────────┼───────┼───────┤\n",
            "│ Schizo.csv                          │ GradientBoostingClassifier │      1     │ 1     │ 1     │\n",
            "├─────────────────────────────────────┼────────────────────────────┼────────────┼───────┼───────┤\n",
            "│ PimaIndiansDiabetesDatabase.csv     │ GradientBoostingClassifier │      0.754 │ 0.711 │ 0.819 │\n",
            "╘═════════════════════════════════════╧════════════════════════════╧════════════╧═══════╧═══════╛\n"
          ]
        }
      ]
    }
  ]
}